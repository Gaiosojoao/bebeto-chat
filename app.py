import streamlit as st
from main_chatbot import resposta_bot

# T칤tulo streamlit app
st.cache_data.clear()
st.cache_resource.clear()

st.title(f""":rainbow[BebetoBot 游뱇游낕]""")

# Limpar cache de dados e recursos
st.cache_data.clear()
st.cache_resource.clear()

# Configurando valores para o estado da sess칚o
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibir mensagens
st.markdown('<div class="content">', unsafe_allow_html=True)
for role, content in st.session_state.messages:
    with st.chat_message(role):
        st.markdown(content)
st.markdown('</div>', unsafe_allow_html=True)

# Adicionando alguns efeitos especiais do ponto de vista da interface do usu치rio
st.balloons()

# Avaliando st.chat_input e determinando se uma pergunta foi inserida
if question := st.chat_input("Fa칞a uma pergunta ao BebetoBot"):
    # Com o 칤cone do usu치rio, escreva a pergunta na interface
    with st.chat_message("user"):
        st.markdown(question)
    # Adicionando a pergunta e o papel (usu치rio) como uma mensagem ao estado da sess칚o
    st.session_state.messages.append(("user", question))
    # Respondendo como assistente com a resposta
    with st.chat_message("assistant"):
        # Garantindo que n칚o haja mensagens presentes ao gerar a resposta
        message_placeholder = st.empty()
        # Colocando um 칤cone de carregamento para mostrar que a consulta est치 em andamento
        with st.spinner("Determinando a melhor resposta poss칤vel!"):
            # Passando a pergunta para a fun칞칚o de busca, que posteriormente invoca o LLM
            answer = resposta_bot(st.session_state.messages)
            # Escrevendo a resposta na interface
            message_placeholder.markdown(f"{answer}")
    # Adicionando os resultados ao estado da sess칚o
    st.session_state.messages.append(("assistant", answer))